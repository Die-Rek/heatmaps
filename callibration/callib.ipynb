{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callibration for Gent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 11 persons, 3 suitcases, 89.5ms\n",
      "Speed: 4.0ms preprocess, 89.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[720.4019165039062, 999.85205078125]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "617"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "612"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "823"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "999"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "239166"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[1966.7950439453125, 445.60504150390625]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1925"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "147"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2008"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "445"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "74202"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[2145.97412109375, 545.794921875]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2087"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "232"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2204"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "545"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "109863"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[432.7463073730469, 547.9089965820312]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "348"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "316"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "517"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "547"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "117117"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[984.0540771484375, 849.0216064453125]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "894"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "463"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1073"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "849"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "207282"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[601.3551025390625, 454.3695068359375]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "545"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "229"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "657"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "454"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "75600"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[1314.107177734375, 516.4038696289062]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1249"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "398"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1378"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "516"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "45666"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[216.78530883789062, 863.028564453125]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "151"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "636"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "281"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "863"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "88530"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[669.9852294921875, 310.15325927734375]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "633"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "143"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "706"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "310"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "36573"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[2358.85888671875, 541.039794921875]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2324"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "306"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2393"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "541"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "48645"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[341.12353515625, 730.5284423828125]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "233"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "421"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "448"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "730"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "199305"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[152.33151245117188, 906.4309692382812]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "646"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "245"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "906"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "145080"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[1071.8314208984375, 442.987548828125]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1041"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "370"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1102"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "442"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "13176"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[290.182373046875, 1267.17578125]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "221"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1113"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "359"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1267"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "63756"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 11 persons, 2 suitcases, 76.2ms\n",
      "Speed: 2.3ms preprocess, 76.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[721.157470703125, 1004.9002685546875]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "617"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "612"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "824"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1004"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "243432"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[1967.338623046875, 443.21356201171875]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1926"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "149"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2008"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "443"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "72324"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[2140.07568359375, 547.0527954101562]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2085"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "219"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2194"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "547"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "107256"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[983.89697265625, 849.7601318359375]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "892"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "462"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1075"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "849"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "212463"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[731.7022705078125, 419.52032470703125]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "678"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "192"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "419"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "72186"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[2434.015625, 567.4492797851562]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2325"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "210"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2542"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "567"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "232407"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[229.02366638183594, 877.010986328125]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "157"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "625"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "877"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "108108"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[445.98651123046875, 548.6080322265625]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "374"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "306"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "516"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "548"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "103092"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[600.2916259765625, 439.9630126953125]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "541"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "230"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "659"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "439"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "73986"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[1315.483642578125, 515.4745483398438]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1252"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "399"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1378"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "515"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "43848"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[291.7586669921875, 1266.9080810546875]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "224"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1114"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "359"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1266"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "61560"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[2161.06640625, 540.6309814453125]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2089"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "186"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2232"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "540"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "151866"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[2200.59716796875, 396.05364990234375]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2167"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "155"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2233"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "396"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "47718"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Escape hit, closing...\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "\n",
    "model = YOLO(\"../yolov8n.pt\")\n",
    "camera = cv2.VideoCapture(\"D:/nike downloads/Antwerpen_07-05_1400-1500/Nike Antwerpen_ch2_20240506140000_20240506143000.mp4\")\n",
    "img_counter = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = camera.read()\n",
    "\n",
    "    if not ret:\n",
    "        print(\"failed to grab frame\")\n",
    "        break\n",
    "    cv2.imshow(\"test\", frame)\n",
    "\n",
    "    k = cv2.waitKey(1)\n",
    "    if k%256 == 27:\n",
    "        # ESC pressed\n",
    "        print(\"Escape hit, closing...\")\n",
    "        break\n",
    "    elif k%256 == 32:\n",
    "        # SPACE pressed\n",
    "        img_path = \"../callibration_frames/Frame_{}.jpg\".format(img_counter)\n",
    "        cv2.imwrite(img_path, frame)\n",
    "        outs = model.predict(frame)\n",
    "        boxes = outs[0].boxes\n",
    "        extracted_counter = 0\n",
    "        for i in range(len(boxes)):\n",
    "            feet = [float(boxes[i].xyxy[0][2] - ((boxes[i].xyxy[0][2] - boxes[i].xyxy[0][0]) /2)), float(boxes[i].xyxy[0][3])]\n",
    "            display(feet)\n",
    "            feet = [int(x) for x in feet]\n",
    "            colored_frame = cv2.circle(frame, (feet[0], feet[1]), radius=1, color=(0,255,0), thickness=2)\n",
    "            named_frame = cv2.putText(colored_frame, str(feet), (feet[0] + 10, feet[1]), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 1, cv2.LINE_AA)\n",
    "            x=int(boxes[i].xyxy[0][0].item())\n",
    "            y=int(boxes[i].xyxy[0][1].item())\n",
    "            w=int(boxes[i].xyxy[0][2].item())\n",
    "            h=int(boxes[i].xyxy[0][3].item())\n",
    "            display(x, y, w, h)\n",
    "            extracted_image = frame[y:h,x:w]\n",
    "            display(extracted_image.size)\n",
    "            if extracted_image.size > 0:\n",
    "                cv2.imshow(\"valid\", extracted_image)\n",
    "                cv2.resizeWindow(\"valid\", 600, 600)\n",
    "                extracted_counter += 1\n",
    "                extracted_image_path = \"../callibration_frames/Frame_{}_{}.jpg\".format(img_counter, extracted_counter)\n",
    "                cv2.imwrite(extracted_image_path, extracted_image)\n",
    "        cv2.imwrite(img_path, named_frame)\n",
    "        img_counter += 1\n",
    "\n",
    "camera.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 5 Persons, 80.3ms\n",
      "Speed: 3.1ms preprocess, 80.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([0., 0., 0., 0., 0.])\n",
      "conf: tensor([0.8161, 0.7455, 0.7094, 0.4920, 0.4325])\n",
      "data: tensor([[1.4501e+03, 1.4301e+02, 1.5552e+03, 4.2609e+02, 8.1614e-01, 0.0000e+00],\n",
      "        [4.4150e+02, 3.9799e+02, 5.8581e+02, 6.6987e+02, 7.4548e-01, 0.0000e+00],\n",
      "        [3.5015e+02, 4.0613e+02, 4.7366e+02, 7.1206e+02, 7.0942e-01, 0.0000e+00],\n",
      "        [7.2226e+02, 4.6421e+02, 9.1423e+02, 8.6517e+02, 4.9203e-01, 0.0000e+00],\n",
      "        [6.2228e+02, 3.1490e+02, 7.5346e+02, 6.6580e+02, 4.3254e-01, 0.0000e+00]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (1440, 2560)\n",
      "shape: torch.Size([5, 6])\n",
      "xywh: tensor([[1502.6918,  284.5486,  105.1006,  283.0757],\n",
      "        [ 513.6538,  533.9267,  144.3103,  271.8774],\n",
      "        [ 411.9041,  559.0912,  123.5120,  305.9296],\n",
      "        [ 818.2432,  664.6897,  191.9669,  400.9519],\n",
      "        [ 687.8700,  490.3458,  131.1777,  350.9016]])\n",
      "xywhn: tensor([[0.5870, 0.1976, 0.0411, 0.1966],\n",
      "        [0.2006, 0.3708, 0.0564, 0.1888],\n",
      "        [0.1609, 0.3883, 0.0482, 0.2125],\n",
      "        [0.3196, 0.4616, 0.0750, 0.2784],\n",
      "        [0.2687, 0.3405, 0.0512, 0.2437]])\n",
      "xyxy: tensor([[1450.1415,  143.0108, 1555.2421,  426.0865],\n",
      "        [ 441.4987,  397.9880,  585.8090,  669.8654],\n",
      "        [ 350.1481,  406.1265,  473.6602,  712.0560],\n",
      "        [ 722.2597,  464.2137,  914.2266,  865.1656],\n",
      "        [ 622.2811,  314.8950,  753.4589,  665.7966]])\n",
      "xyxyn: tensor([[0.5665, 0.0993, 0.6075, 0.2959],\n",
      "        [0.1725, 0.2764, 0.2288, 0.4652],\n",
      "        [0.1368, 0.2820, 0.1850, 0.4945],\n",
      "        [0.2821, 0.3224, 0.3571, 0.6008],\n",
      "        [0.2431, 0.2187, 0.2943, 0.4624]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1502.6917724609375, 426.0864562988281]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([0., 0., 0., 0., 0.])\n",
      "conf: tensor([0.8161, 0.7455, 0.7094, 0.4920, 0.4325])\n",
      "data: tensor([[1.4501e+03, 1.4301e+02, 1.5552e+03, 4.2609e+02, 8.1614e-01, 0.0000e+00],\n",
      "        [4.4150e+02, 3.9799e+02, 5.8581e+02, 6.6987e+02, 7.4548e-01, 0.0000e+00],\n",
      "        [3.5015e+02, 4.0613e+02, 4.7366e+02, 7.1206e+02, 7.0942e-01, 0.0000e+00],\n",
      "        [7.2226e+02, 4.6421e+02, 9.1423e+02, 8.6517e+02, 4.9203e-01, 0.0000e+00],\n",
      "        [6.2228e+02, 3.1490e+02, 7.5346e+02, 6.6580e+02, 4.3254e-01, 0.0000e+00]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (1440, 2560)\n",
      "shape: torch.Size([5, 6])\n",
      "xywh: tensor([[1502.6918,  284.5486,  105.1006,  283.0757],\n",
      "        [ 513.6538,  533.9267,  144.3103,  271.8774],\n",
      "        [ 411.9041,  559.0912,  123.5120,  305.9296],\n",
      "        [ 818.2432,  664.6897,  191.9669,  400.9519],\n",
      "        [ 687.8700,  490.3458,  131.1777,  350.9016]])\n",
      "xywhn: tensor([[0.5870, 0.1976, 0.0411, 0.1966],\n",
      "        [0.2006, 0.3708, 0.0564, 0.1888],\n",
      "        [0.1609, 0.3883, 0.0482, 0.2125],\n",
      "        [0.3196, 0.4616, 0.0750, 0.2784],\n",
      "        [0.2687, 0.3405, 0.0512, 0.2437]])\n",
      "xyxy: tensor([[1450.1415,  143.0108, 1555.2421,  426.0865],\n",
      "        [ 441.4987,  397.9880,  585.8090,  669.8654],\n",
      "        [ 350.1481,  406.1265,  473.6602,  712.0560],\n",
      "        [ 722.2597,  464.2137,  914.2266,  865.1656],\n",
      "        [ 622.2811,  314.8950,  753.4589,  665.7966]])\n",
      "xyxyn: tensor([[0.5665, 0.0993, 0.6075, 0.2959],\n",
      "        [0.1725, 0.2764, 0.2288, 0.4652],\n",
      "        [0.1368, 0.2820, 0.1850, 0.4945],\n",
      "        [0.2821, 0.3224, 0.3571, 0.6008],\n",
      "        [0.2431, 0.2187, 0.2943, 0.4624]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[513.65380859375, 669.8654174804688]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([0., 0., 0., 0., 0.])\n",
      "conf: tensor([0.8161, 0.7455, 0.7094, 0.4920, 0.4325])\n",
      "data: tensor([[1.4501e+03, 1.4301e+02, 1.5552e+03, 4.2609e+02, 8.1614e-01, 0.0000e+00],\n",
      "        [4.4150e+02, 3.9799e+02, 5.8581e+02, 6.6987e+02, 7.4548e-01, 0.0000e+00],\n",
      "        [3.5015e+02, 4.0613e+02, 4.7366e+02, 7.1206e+02, 7.0942e-01, 0.0000e+00],\n",
      "        [7.2226e+02, 4.6421e+02, 9.1423e+02, 8.6517e+02, 4.9203e-01, 0.0000e+00],\n",
      "        [6.2228e+02, 3.1490e+02, 7.5346e+02, 6.6580e+02, 4.3254e-01, 0.0000e+00]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (1440, 2560)\n",
      "shape: torch.Size([5, 6])\n",
      "xywh: tensor([[1502.6918,  284.5486,  105.1006,  283.0757],\n",
      "        [ 513.6538,  533.9267,  144.3103,  271.8774],\n",
      "        [ 411.9041,  559.0912,  123.5120,  305.9296],\n",
      "        [ 818.2432,  664.6897,  191.9669,  400.9519],\n",
      "        [ 687.8700,  490.3458,  131.1777,  350.9016]])\n",
      "xywhn: tensor([[0.5870, 0.1976, 0.0411, 0.1966],\n",
      "        [0.2006, 0.3708, 0.0564, 0.1888],\n",
      "        [0.1609, 0.3883, 0.0482, 0.2125],\n",
      "        [0.3196, 0.4616, 0.0750, 0.2784],\n",
      "        [0.2687, 0.3405, 0.0512, 0.2437]])\n",
      "xyxy: tensor([[1450.1415,  143.0108, 1555.2421,  426.0865],\n",
      "        [ 441.4987,  397.9880,  585.8090,  669.8654],\n",
      "        [ 350.1481,  406.1265,  473.6602,  712.0560],\n",
      "        [ 722.2597,  464.2137,  914.2266,  865.1656],\n",
      "        [ 622.2811,  314.8950,  753.4589,  665.7966]])\n",
      "xyxyn: tensor([[0.5665, 0.0993, 0.6075, 0.2959],\n",
      "        [0.1725, 0.2764, 0.2288, 0.4652],\n",
      "        [0.1368, 0.2820, 0.1850, 0.4945],\n",
      "        [0.2821, 0.3224, 0.3571, 0.6008],\n",
      "        [0.2431, 0.2187, 0.2943, 0.4624]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[411.9041442871094, 712.0560302734375]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([0., 0., 0., 0., 0.])\n",
      "conf: tensor([0.8161, 0.7455, 0.7094, 0.4920, 0.4325])\n",
      "data: tensor([[1.4501e+03, 1.4301e+02, 1.5552e+03, 4.2609e+02, 8.1614e-01, 0.0000e+00],\n",
      "        [4.4150e+02, 3.9799e+02, 5.8581e+02, 6.6987e+02, 7.4548e-01, 0.0000e+00],\n",
      "        [3.5015e+02, 4.0613e+02, 4.7366e+02, 7.1206e+02, 7.0942e-01, 0.0000e+00],\n",
      "        [7.2226e+02, 4.6421e+02, 9.1423e+02, 8.6517e+02, 4.9203e-01, 0.0000e+00],\n",
      "        [6.2228e+02, 3.1490e+02, 7.5346e+02, 6.6580e+02, 4.3254e-01, 0.0000e+00]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (1440, 2560)\n",
      "shape: torch.Size([5, 6])\n",
      "xywh: tensor([[1502.6918,  284.5486,  105.1006,  283.0757],\n",
      "        [ 513.6538,  533.9267,  144.3103,  271.8774],\n",
      "        [ 411.9041,  559.0912,  123.5120,  305.9296],\n",
      "        [ 818.2432,  664.6897,  191.9669,  400.9519],\n",
      "        [ 687.8700,  490.3458,  131.1777,  350.9016]])\n",
      "xywhn: tensor([[0.5870, 0.1976, 0.0411, 0.1966],\n",
      "        [0.2006, 0.3708, 0.0564, 0.1888],\n",
      "        [0.1609, 0.3883, 0.0482, 0.2125],\n",
      "        [0.3196, 0.4616, 0.0750, 0.2784],\n",
      "        [0.2687, 0.3405, 0.0512, 0.2437]])\n",
      "xyxy: tensor([[1450.1415,  143.0108, 1555.2421,  426.0865],\n",
      "        [ 441.4987,  397.9880,  585.8090,  669.8654],\n",
      "        [ 350.1481,  406.1265,  473.6602,  712.0560],\n",
      "        [ 722.2597,  464.2137,  914.2266,  865.1656],\n",
      "        [ 622.2811,  314.8950,  753.4589,  665.7966]])\n",
      "xyxyn: tensor([[0.5665, 0.0993, 0.6075, 0.2959],\n",
      "        [0.1725, 0.2764, 0.2288, 0.4652],\n",
      "        [0.1368, 0.2820, 0.1850, 0.4945],\n",
      "        [0.2821, 0.3224, 0.3571, 0.6008],\n",
      "        [0.2431, 0.2187, 0.2943, 0.4624]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[818.2431640625, 865.1656494140625]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([0., 0., 0., 0., 0.])\n",
      "conf: tensor([0.8161, 0.7455, 0.7094, 0.4920, 0.4325])\n",
      "data: tensor([[1.4501e+03, 1.4301e+02, 1.5552e+03, 4.2609e+02, 8.1614e-01, 0.0000e+00],\n",
      "        [4.4150e+02, 3.9799e+02, 5.8581e+02, 6.6987e+02, 7.4548e-01, 0.0000e+00],\n",
      "        [3.5015e+02, 4.0613e+02, 4.7366e+02, 7.1206e+02, 7.0942e-01, 0.0000e+00],\n",
      "        [7.2226e+02, 4.6421e+02, 9.1423e+02, 8.6517e+02, 4.9203e-01, 0.0000e+00],\n",
      "        [6.2228e+02, 3.1490e+02, 7.5346e+02, 6.6580e+02, 4.3254e-01, 0.0000e+00]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (1440, 2560)\n",
      "shape: torch.Size([5, 6])\n",
      "xywh: tensor([[1502.6918,  284.5486,  105.1006,  283.0757],\n",
      "        [ 513.6538,  533.9267,  144.3103,  271.8774],\n",
      "        [ 411.9041,  559.0912,  123.5120,  305.9296],\n",
      "        [ 818.2432,  664.6897,  191.9669,  400.9519],\n",
      "        [ 687.8700,  490.3458,  131.1777,  350.9016]])\n",
      "xywhn: tensor([[0.5870, 0.1976, 0.0411, 0.1966],\n",
      "        [0.2006, 0.3708, 0.0564, 0.1888],\n",
      "        [0.1609, 0.3883, 0.0482, 0.2125],\n",
      "        [0.3196, 0.4616, 0.0750, 0.2784],\n",
      "        [0.2687, 0.3405, 0.0512, 0.2437]])\n",
      "xyxy: tensor([[1450.1415,  143.0108, 1555.2421,  426.0865],\n",
      "        [ 441.4987,  397.9880,  585.8090,  669.8654],\n",
      "        [ 350.1481,  406.1265,  473.6602,  712.0560],\n",
      "        [ 722.2597,  464.2137,  914.2266,  865.1656],\n",
      "        [ 622.2811,  314.8950,  753.4589,  665.7966]])\n",
      "xyxyn: tensor([[0.5665, 0.0993, 0.6075, 0.2959],\n",
      "        [0.1725, 0.2764, 0.2288, 0.4652],\n",
      "        [0.1368, 0.2820, 0.1850, 0.4945],\n",
      "        [0.2821, 0.3224, 0.3571, 0.6008],\n",
      "        [0.2431, 0.2187, 0.2943, 0.4624]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[687.8699951171875, 665.796630859375]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Escape hit, closing...\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "model = YOLO(\"../model_- 15 april 2024 18_14.pt\")\n",
    "camera = cv2.VideoCapture(\"D:/nike downloads/Antwerpen_07-05_1400-1500/Nike Antwerpen_ch4_20240506140000_20240506143000.mp4\")\n",
    "img_counter = 0\n",
    "allpoints=[]\n",
    "while True:\n",
    "    ret, frame = camera.read()\n",
    "\n",
    "    if not ret:\n",
    "        print(\"failed to grab frame\")\n",
    "        break\n",
    "    cv2.imshow(\"test10\", frame)\n",
    "\n",
    "    k = cv2.waitKey(1)\n",
    "    if k%256 == 27:\n",
    "        # ESC pressed\n",
    "        print(\"Escape hit, closing...\")\n",
    "        break\n",
    "    elif k%256 == 32:\n",
    "        # SPACE pressed\n",
    "        img_path = \"../callibration_frames/Frame_{}.jpg\".format(img_counter)\n",
    "        cv2.imwrite(img_path, frame)\n",
    "        outs = model.predict(frame)\n",
    "        boxes = outs[0].boxes\n",
    "        for i in range(len(boxes)):\n",
    "            print(boxes)\n",
    "            feet = [float(boxes[i].xyxy[0][2] - ((boxes[i].xyxy[0][2] - boxes[i].xyxy[0][0]) /2)), float(boxes[i].xyxy[0][3])]\n",
    "            display(feet)\n",
    "            allpoints.append(feet)\n",
    "            feet = [int(x) for x in feet]\n",
    "            frame = cv2.circle(frame, (feet[0], feet[1]), radius=1, color=(0,255,0), thickness=2)\n",
    "            frame = cv2.putText(frame, str(feet), (feet[0] + 10, feet[1]), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 1, cv2.LINE_AA)\n",
    "            # named_frame = cv2.rectangle(named_frame, (boxes[i].xywh[0], boxes[i].xywh[1]),boxes[i].xywh[0] + boxes[i].xywh[2],  boxes[i].xywh[1] + boxes[i].xywh[3])\n",
    "        cv2.imshow(\"valid\", frame)\n",
    "        cv2.imwrite(img_path, frame)\n",
    "        img_counter += 1\n",
    "\n",
    "camera.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "197640"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_image.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enlarge groundplan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "image = cv2.imread(\"../groundplan/Nike antwerpen.png\")\n",
    "\n",
    "bigger = cv2.resize(image, (800, 2000), interpolation = cv2.INTER_LINEAR)\n",
    "cv2.imwrite(\"../groundplan/Nike_antwerpen_enlarged.png\", image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callibration camera 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[2329.712   ,   33.647762]]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# provide points from image 1\n",
    "pts_src = np.array([[1131, 762], [287, 472], [77, 925],[1750, 939], [1058, 529], [68, 415]\n",
    "                    ])\n",
    "# corresponding points from image 2 (i.e. (154, 174) matches (212, 80))\n",
    "pts_dst = np.array([[2381, 544],[2352, 238],[2222, 387],[2389, 647], [2431,481], [2330, 29]\n",
    "                    ])\n",
    "\n",
    "# calculate matrix H\n",
    "h2, status2 = cv2.findHomography(pts_src, pts_dst)\n",
    "\n",
    "# provide a point you wish to map from image 1 to image 2\n",
    "a = np.array([[68, 415]], dtype='float32')\n",
    "a = np.array([a])\n",
    "\n",
    "# finally, get the mapping\n",
    "pointsOut = cv2.perspectiveTransform(a, h2)\n",
    "pointsOut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callibration for camera 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[     2057.1,      510.56]]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# provide points from image 1\n",
    "pts_src = np.array([[1629, 154], [1135, 534], [1998, 1186],[238, 609], [271, 277], [923, 405], [1068, 155]\n",
    "                    ])\n",
    "# corresponding points from image 2 (i.e. (154, 174) matches (212, 80))\n",
    "pts_dst = np.array([[2330, 29],[2222, 387],[2381, 544],[2034, 455], [1763,181], [2134, 328], [2130, 68]\n",
    "                    ])\n",
    "\n",
    "# calculate matrix H\n",
    "h3, status2 = cv2.findHomography(pts_src, pts_dst)\n",
    "\n",
    "# provide a point you wish to map from image 1 to image 2\n",
    "a = np.array([[230, 730]], dtype='float32')\n",
    "a = np.array([a])\n",
    "\n",
    "# finally, get the mapping\n",
    "pointsOut = cv2.perspectiveTransform(a, h3)\n",
    "pointsOut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callibrate camera 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1975.,  704.]]], dtype=float32)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2 # import the OpenCV library\n",
    "import numpy as np # import the numpy library\n",
    "\n",
    "# provide points from image 1\n",
    "pts_src = np.array([[490, 650], [1704, 1200], [2059, 455], [1863, 136], \n",
    "                    # [962, 1373], [913, 806]\n",
    "                    ])\n",
    "# corresponding points from image 2 (i.e. (154, 174) matches (212, 80))\n",
    "pts_dst = np.array([[1975, 704],[2034, 455],[1700, 417], [1359, 525],\n",
    "                    #  [88,258], [27, 223]\n",
    "                    ])\n",
    "\n",
    "# calculate matrix H\n",
    "h4, status1 = cv2.findHomography(pts_src, pts_dst)\n",
    "\n",
    "# provide a point you wish to map from image 1 to image 2\n",
    "a = np.array([[490, 650]], dtype='float32')\n",
    "a = np.array([a])\n",
    "\n",
    "# finally, get the mapping\n",
    "pointsOut = cv2.perspectiveTransform(a, h4)\n",
    "pointsOut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callibrate camera 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[     2216.5,      142.96]]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2 # import the OpenCV library\n",
    "import numpy as np # import the numpy library\n",
    "\n",
    "# provide points from image 1\n",
    "pts_src = np.array([[468, 604], [1584, 224], [118, 797], [1251, 384], [1029, 1113]\n",
    "                    # [465, 476]\n",
    "                    # [913, 806]\n",
    "                    ])\n",
    "# corresponding points from image 2 (i.e. (154, 174) matches (212, 80))\n",
    "pts_dst = np.array([[2132, 324],[1840, 151],[2224, 358],[1986, 208], [2215,142]\n",
    "                    # [2084,337]\n",
    "                    # [27, 223]\n",
    "                    ])\n",
    "\n",
    "# calculate matrix H\n",
    "h5, status1 = cv2.findHomography(pts_src, pts_dst)\n",
    "\n",
    "# provide a point you wish to map from image 1 to image 2\n",
    "a = np.array([[1029, 1113]], dtype='float32')\n",
    "a = np.array([a])\n",
    "\n",
    "# finally, get the mapping\n",
    "pointsOut = cv2.perspectiveTransform(a, h5)\n",
    "pointsOut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callibrate camera 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1887.5697 ,  341.45087]]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2 # import the OpenCV library\n",
    "import numpy as np # import the numpy library\n",
    "\n",
    "# provide points from image 1\n",
    "pts_src = np.array([[919, 1311], [886, 427], [313, 1305], [19, 438], \n",
    "                    # [219, 808], \n",
    "                    # [913, 806]\n",
    "                    ])\n",
    "# corresponding points from image 2 (i.e. (154, 174) matches (212, 80))\n",
    "pts_dst = np.array([[1840, 151],[1674, 415],[1909, 206],[1920, 706], \n",
    "                    # [1879,334], \n",
    "                    # [27, 223]\n",
    "                    ])\n",
    "\n",
    "# calculate matrix H\n",
    "h6, status1 = cv2.findHomography(pts_src, pts_dst)\n",
    "\n",
    "# provide a point you wish to map from image 1 to image 2\n",
    "a = np.array([[274, 808]], dtype='float32')\n",
    "a = np.array([a])\n",
    "\n",
    "# finally, get the mapping\n",
    "pointsOut = cv2.perspectiveTransform(a, h6)\n",
    "pointsOut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callibrate camera 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[765.7831, 220.3334]]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2 # import the OpenCV library\n",
    "import numpy as np # import the numpy library\n",
    "\n",
    "# provide points from image 1\n",
    "pts_src = np.array([[1605, 926], [425, 494], [316, 1368],  [2152, 630], [146, 135], [1994, 539]\n",
    "                    # [913, 806]\n",
    "                    ])\n",
    "# corresponding points from image 2 (i.e. (154, 174) matches (212, 80))\n",
    "pts_dst = np.array([[1984, 238],[1702, 415],[2031, 455], [1973,35], [406, 747], [1918, 35]\n",
    "                    # [27, 223]\n",
    "                    ])\n",
    "\n",
    "# calculate matrix H\n",
    "h7, status1 = cv2.findHomography(pts_src, pts_dst)\n",
    "\n",
    "# provide a point you wish to map from image 1 to image 2\n",
    "a = np.array([[588, 112]], dtype='float32')\n",
    "a = np.array([a])\n",
    "\n",
    "# finally, get the mapping\n",
    "pointsOut = cv2.perspectiveTransform(a, h7)\n",
    "pointsOut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callibrate camera 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[921.6831, 646.8048]]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TODO\n",
    "\n",
    "import cv2 # import the OpenCV library\n",
    "import numpy as np # import the numpy library\n",
    "\n",
    "# provide points from image 1\n",
    "pts_src = np.array([[1317, 337], [2172, 898], [2173, 467], [2080, 340], [279, 53], \n",
    "                    # [913, 806]\n",
    "                    ])\n",
    "# corresponding points from image 2 (i.e. (154, 174) matches (212, 80))\n",
    "pts_dst = np.array([[1700, 413],[2032, 455],[1909, 240],[1842, 151], [467,618], \n",
    "                    # [27, 223]\n",
    "                    ])\n",
    "\n",
    "# calculate matrix H\n",
    "h8, status1 = cv2.findHomography(pts_src, pts_dst)\n",
    "\n",
    "# provide a point you wish to map from image 1 to image 2\n",
    "a = np.array([[286, 116]], dtype='float32')\n",
    "a = np.array([a])\n",
    "\n",
    "# finally, get the mapping\n",
    "pointsOut = cv2.perspectiveTransform(a, h8)\n",
    "pointsOut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callibrate camera 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 27.230206, 222.00674 ]]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#TODO\n",
    "\n",
    "import cv2 # import the OpenCV library\n",
    "import numpy as np # import the numpy library\n",
    "\n",
    "# provide points from image 1\n",
    "pts_src = np.array([[626, 509], [1917, 110], [1108, 382], [2389, 177],\n",
    "                    #  [376, 699], [272, 384]\n",
    "                    ])\n",
    "# corresponding points from image 2 (i.e. (154, 174) matches (212, 80))\n",
    "pts_dst = np.array([[1428, 415],[2034, 455],[1556, 432],[2392, 647],\n",
    "                    #  [1388,435], [1379, 251]\n",
    "                    ])\n",
    "\n",
    "# calculate matrix H\n",
    "h9, status1 = cv2.findHomography(pts_src, pts_dst)\n",
    "\n",
    "# provide a point you wish to map from image 1 to image 2\n",
    "a = np.array([[913, 806]], dtype='float32')\n",
    "a = np.array([a])\n",
    "\n",
    "# finally, get the mapping\n",
    "pointsOut = cv2.perspectiveTransform(a, h9) \n",
    "pointsOut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callibrate camera 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 27.230206, 222.00674 ]]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#TODO\n",
    "\n",
    "import cv2 # import the OpenCV library\n",
    "import numpy as np # import the numpy library\n",
    "\n",
    "# provide points from image 1\n",
    "pts_src = np.array([[1399, 107], [2050, 377], [1175, 303], [1871, 3],\n",
    "                    #  [376, 699], [272, 384]\n",
    "                    ])\n",
    "# corresponding points from image 2 (i.e. (154, 174) matches (212, 80))\n",
    "pts_dst = np.array([[1907, 236],[1671, 415],[1691, 144],[2376, 647],\n",
    "                    #  [1388,435], [1379, 251]\n",
    "                    ])\n",
    "\n",
    "# calculate matrix H\n",
    "h9, status1 = cv2.findHomography(pts_src, pts_dst)\n",
    "\n",
    "# provide a point you wish to map from image 1 to image 2\n",
    "a = np.array([[913, 806]], dtype='float32')\n",
    "a = np.array([a])\n",
    "\n",
    "# finally, get the mapping\n",
    "pointsOut = cv2.perspectiveTransform(a, h9) \n",
    "pointsOut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callibrate camera 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 27.230206, 222.00674 ]]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#TODO\n",
    "\n",
    "import cv2 # import the OpenCV library\n",
    "import numpy as np # import the numpy library\n",
    "\n",
    "# provide points from image 1\n",
    "pts_src = np.array([[130, 916], [963, 367], [2343, 323], [1228, 35],\n",
    "                    #  [376, 699], [272, 384]\n",
    "                    ])\n",
    "# corresponding points from image 2 (i.e. (154, 174) matches (212, 80))\n",
    "pts_dst = np.array([[1438, 415],[1287, 708],[609, 804],[1202, 706],\n",
    "                    #  [1388,435], [1379, 251]\n",
    "                    ])\n",
    "\n",
    "# calculate matrix H\n",
    "h9, status1 = cv2.findHomography(pts_src, pts_dst)\n",
    "\n",
    "# provide a point you wish to map from image 1 to image 2\n",
    "a = np.array([[913, 806]], dtype='float32')\n",
    "a = np.array([a])\n",
    "\n",
    "# finally, get the mapping\n",
    "pointsOut = cv2.perspectiveTransform(a, h9) \n",
    "pointsOut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callibrate camera 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 27.230206, 222.00674 ]]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#TODO\n",
    "\n",
    "import cv2 # import the OpenCV library\n",
    "import numpy as np # import the numpy library\n",
    "\n",
    "# provide points from image 1\n",
    "pts_src = np.array([[127, 518], [1910, 429], [1398, 349], [2553, 798],\n",
    "                    #  [376, 699], [272, 384]\n",
    "                    ])\n",
    "# corresponding points from image 2 (i.e. (154, 174) matches (212, 80))\n",
    "pts_dst = np.array([[689, 354],[1272, 208],[1091, 199],[1434, 415],\n",
    "                    #  [1388,435], [1379, 251]\n",
    "                    ])\n",
    "\n",
    "# calculate matrix H\n",
    "h9, status1 = cv2.findHomography(pts_src, pts_dst)\n",
    "\n",
    "# provide a point you wish to map from image 1 to image 2\n",
    "a = np.array([[913, 806]], dtype='float32')\n",
    "a = np.array([a])\n",
    "\n",
    "# finally, get the mapping\n",
    "pointsOut = cv2.perspectiveTransform(a, h9) \n",
    "pointsOut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callibrate camera 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[334.74234, 977.9425 ]]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TODO\n",
    "\n",
    "import cv2 # import the OpenCV library\n",
    "import numpy as np # import the numpy library\n",
    "\n",
    "# provide points from image 1\n",
    "pts_src = np.array([[916, 263], [718, 271], [391, 284], [834, 209],[46, 313], [1273, 1160]\n",
    "                    #  [376, 699], [272, 384]\n",
    "                    ])\n",
    "# corresponding points from image 2 (i.e. (154, 174) matches (212, 80))\n",
    "pts_dst = np.array([[449, 437],[469, 505],[467, 669],[373, 503],[408, 1031], [833, 251]\n",
    "                    #  [1388,435], [1379, 251]\n",
    "                    ])\n",
    "\n",
    "# calculate matrix H\n",
    "h9, status1 = cv2.findHomography(pts_src, pts_dst)\n",
    "\n",
    "# provide a point you wish to map from image 1 to image 2\n",
    "a = np.array([[154, 277]], dtype='float32')\n",
    "a = np.array([a])\n",
    "\n",
    "# finally, get the mapping\n",
    "pointsOut = cv2.perspectiveTransform(a, h9) \n",
    "pointsOut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callibrate camera 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 27.230206, 222.00674 ]]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#TODO\n",
    "\n",
    "import cv2 # import the OpenCV library\n",
    "import numpy as np # import the numpy library\n",
    "\n",
    "# provide points from image 1\n",
    "pts_src = np.array([[1739, 239], [2072, 161], [1622, 196], [2021, 140],\n",
    "                    #  [376, 699], [272, 384]\n",
    "                    ])\n",
    "# corresponding points from image 2 (i.e. (154, 174) matches (212, 80))\n",
    "pts_dst = np.array([[960, 195],[1274, 238],[958, 142],[1274, 208],\n",
    "                    #  [1388,435], [1379, 251]\n",
    "                    ])\n",
    "\n",
    "# calculate matrix H\n",
    "h9, status1 = cv2.findHomography(pts_src, pts_dst)\n",
    "\n",
    "# provide a point you wish to map from image 1 to image 2\n",
    "a = np.array([[913, 806]], dtype='float32')\n",
    "a = np.array([a])\n",
    "\n",
    "# finally, get the mapping\n",
    "pointsOut = cv2.perspectiveTransform(a, h9) \n",
    "pointsOut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callibrate camera 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[4124.901, 3554.158]]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TODO\n",
    "\n",
    "import cv2 # import the OpenCV library\n",
    "import numpy as np # import the numpy library\n",
    "\n",
    "# provide points from image 1\n",
    "pts_src = np.array([[775, 445], [993, 393], [2266, 582], [2542, 626],[2232,984]\n",
    "                    #  [376, 699], [272, 384]\n",
    "                    ])\n",
    "# corresponding points from image 2 (i.e. (154, 174) matches (212, 80))\n",
    "pts_dst = np.array([[807, 1033],[740, 1036],[471, 802],[408, 749],[609,747]\n",
    "                    #  [1388,435], [1379, 251]\n",
    "                    ])\n",
    "\n",
    "# calculate matrix H\n",
    "h9, status1 = cv2.findHomography(pts_src, pts_dst)\n",
    "\n",
    "# provide a point you wish to map from image 1 to image 2\n",
    "a = np.array([[1919, 586]], dtype='float32')\n",
    "a = np.array([a])\n",
    "\n",
    "# finally, get the mapping\n",
    "pointsOut = cv2.perspectiveTransform(a, h9) \n",
    "pointsOut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callibrate camera 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 27.230206, 222.00674 ]]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#TODO\n",
    "\n",
    "import cv2 # import the OpenCV library\n",
    "import numpy as np # import the numpy library\n",
    "\n",
    "# provide points from image 1\n",
    "pts_src = np.array([[472, 379], [754, 285], [2187, 589], [853, 219],\n",
    "                    #  [376, 699], [272, 384]\n",
    "                    ])\n",
    "# corresponding points from image 2 (i.e. (154, 174) matches (212, 80))\n",
    "pts_dst = np.array([[408, 747],[469, 675],[873, 728],[469, 618],\n",
    "                    #  [1388,435], [1379, 251]\n",
    "                    ])\n",
    "\n",
    "# calculate matrix H\n",
    "h9, status1 = cv2.findHomography(pts_src, pts_dst)\n",
    "\n",
    "# provide a point you wish to map from image 1 to image 2\n",
    "a = np.array([[913, 806]], dtype='float32')\n",
    "a = np.array([a])\n",
    "\n",
    "# finally, get the mapping\n",
    "pointsOut = cv2.perspectiveTransform(a, h9) \n",
    "pointsOut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callibrate camera 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 27.230206, 222.00674 ]]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#TODO\n",
    "\n",
    "import cv2 # import the OpenCV library\n",
    "import numpy as np # import the numpy library\n",
    "\n",
    "# provide points from image 1\n",
    "pts_src = np.array([[864, 389], [2278, 233], [775, 579], [585, 1102],\n",
    "                    #  [376, 699], [272, 384]\n",
    "                    ])\n",
    "# corresponding points from image 2 (i.e. (154, 174) matches (212, 80))\n",
    "pts_dst = np.array([[379, 439],[956, 142],[375, 505],[377, 620],\n",
    "                    #  [1388,435], [1379, 251]\n",
    "                    ])\n",
    "\n",
    "# calculate matrix H\n",
    "h9, status1 = cv2.findHomography(pts_src, pts_dst)\n",
    "\n",
    "# provide a point you wish to map from image 1 to image 2\n",
    "a = np.array([[913, 806]], dtype='float32')\n",
    "a = np.array([a])\n",
    "\n",
    "# finally, get the mapping\n",
    "pointsOut = cv2.perspectiveTransform(a, h9) \n",
    "pointsOut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callibrate camera 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 27.230206, 222.00674 ]]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#TODO\n",
    "\n",
    "import cv2 # import the OpenCV library\n",
    "import numpy as np # import the numpy library\n",
    "\n",
    "# provide points from image 1\n",
    "pts_src = np.array([[915, 1129], [1246, 1111], [1731, 1069], [1473, 165],\n",
    "                    #  [376, 699], [272, 384]\n",
    "                    ])\n",
    "# corresponding points from image 2 (i.e. (154, 174) matches (212, 80))\n",
    "pts_dst = np.array([[467, 507],[434, 505],[377, 503],[373, 675],\n",
    "                    #  [1388,435], [1379, 251]\n",
    "                    ])\n",
    "\n",
    "# calculate matrix H\n",
    "h9, status1 = cv2.findHomography(pts_src, pts_dst)\n",
    "\n",
    "# provide a point you wish to map from image 1 to image 2\n",
    "a = np.array([[913, 806]], dtype='float32')\n",
    "a = np.array([a])\n",
    "\n",
    "# finally, get the mapping\n",
    "pointsOut = cv2.perspectiveTransform(a, h9) \n",
    "pointsOut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callibrate camera 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 27.230206, 222.00674 ]]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#TODO\n",
    "\n",
    "import cv2 # import the OpenCV library\n",
    "import numpy as np # import the numpy library\n",
    "\n",
    "# provide points from image 1\n",
    "pts_src = np.array([[1532, 585], [1822, 877], [1693, 1320], [1147, 1149],\n",
    "                    #  [376, 699], [272, 384]\n",
    "                    ])\n",
    "# corresponding points from image 2 (i.e. (154, 174) matches (212, 80))\n",
    "pts_dst = np.array([[899, 723],[962, 778],[964, 854],[892, 859],\n",
    "                    #  [1388,435], [1379, 251]\n",
    "                    ])\n",
    "\n",
    "# calculate matrix H\n",
    "h9, status1 = cv2.findHomography(pts_src, pts_dst)\n",
    "\n",
    "# provide a point you wish to map from image 1 to image 2\n",
    "a = np.array([[913, 806]], dtype='float32')\n",
    "a = np.array([a])\n",
    "\n",
    "# finally, get the mapping\n",
    "pointsOut = cv2.perspectiveTransform(a, h9) \n",
    "pointsOut"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
